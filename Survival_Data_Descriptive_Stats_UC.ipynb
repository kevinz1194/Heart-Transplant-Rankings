{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139a0dd1",
   "metadata": {},
   "source": [
    "### This notebook calculates descriptive statistics for each variable.\n",
    "> Categorical variables are described using the total count and percentage of individuals with that characteristic. <br>\n",
    "> Continuous variables are described using the median (50th percentile), 25th percentile, and 75th percentile. <br>\n",
    "> To compare the early cohort to the later cohort, Wilcoxon rank-sum tests are performed for continuous variables. <br>\n",
    "> Chi-squared tests are used to compare the cohorts with categorical variables. <br>\n",
    "\n",
    "### *Before running this notebook, it is necessary to run Survival_Data_Initial_Processing_UC.ipynb*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad45758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472\n"
     ]
    }
   ],
   "source": [
    "#Run data processing notebook\n",
    "%run /Users/kevinz94/Desktop/HeartDataPipeline/Survival_Data_Initial_Processing_UC.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b92bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (diag_ct) that has the number of individuals with each diagnosis\n",
    "\n",
    "#Because diagnosis variables are 1 for individuals with a given diagnosis, and 0 otherwise\n",
    "#We can find the number of patients with that diagnosis simply by summing over the column\n",
    "#The columns of the contingency table are as follows, in order\n",
    "#Nonischemic dilated cardiomyopathy\n",
    "#Ischemic cardiomyopathy\n",
    "#Congenital heart disease\n",
    "#Restrictive cardiomyopathy\n",
    "#Hypertrophic cardiomyopathy\n",
    "#Valvular heart disease\n",
    "#Other diagnosis\n",
    "#The first row of the contingency table refers to the early cohort, and the second row refers to the later cohort\n",
    "\n",
    "diag_ct = np.zeros((2,7))\n",
    "\n",
    "diag_ct[0,0] = df_early[\"diag_dilated_CM\"].sum()\n",
    "diag_ct[0,1] = df_early[\"diag_ischemic\"].sum()\n",
    "diag_ct[0,2] = df_early[\"diag_congenital\"].sum()\n",
    "diag_ct[0,3] = df_early[\"diag_restricted\"].sum()\n",
    "diag_ct[0,4] = df_early[\"diag_hypertrophic\"].sum()\n",
    "diag_ct[0,5] = df_early[\"diag_valvular\"].sum()\n",
    "diag_ct[0,6] = df_early[\"diag_OTHER\"].sum()\n",
    "\n",
    "diag_ct[1,0] = df_later[\"diag_dilated_CM\"].sum()\n",
    "diag_ct[1,1] = df_later[\"diag_ischemic\"].sum()\n",
    "diag_ct[1,2] = df_later[\"diag_congenital\"].sum()\n",
    "diag_ct[1,3] = df_later[\"diag_restricted\"].sum()\n",
    "diag_ct[1,4] = df_later[\"diag_hypertrophic\"].sum()\n",
    "diag_ct[1,5] = df_later[\"diag_valvular\"].sum()\n",
    "diag_ct[1,6] = df_later[\"diag_OTHER\"].sum()\n",
    "\n",
    "#Print contingency table to csv\n",
    "total_diag = pd.DataFrame(data=diag_ct,columns=[\"diag_dilated_CM\",\"diag_ischemic\",\"diag_congenital\",\"diag_restricted\",\"diag_hypertrophic\",\"diag_valvular\",\"diag_OTHER\"],index=[\"early\",\"later\"])\n",
    "total_diag.to_csv('total_diagnosis.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((diag_ct.shape[0],diag_ct.shape[1]))\n",
    "perc[0,:] = 100 * (np.divide(diag_ct[0,:],np.sum(diag_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(diag_ct[1,:],np.sum(diag_ct[1,:])))\n",
    "perc_diag = pd.DataFrame(data=perc,columns=[\"diag_dilated_CM\",\"diag_ischemic\",\"diag_congenital\",\"diag_restricted\",\"diag_hypertrophic\",\"diag_valvular\",\"diag_OTHER\"],index=[\"early\",\"later\"])\n",
    "perc_diag.to_csv('percentages_diagnosis.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "diag_p = np.zeros((1,1))\n",
    "diag_p[0,0] = chi2_contingency(diag_ct)[1]\n",
    "p_val_diag = pd.DataFrame(data=diag_p,columns=['p-value of diagnosis'])\n",
    "p_val_diag.to_csv('p_val_diagnosis.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a62cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (diab_ct) that has the number of individuals with and without diabetes\n",
    "\n",
    "#The first column refers to individuals with diabetes, and the second column refers to people without diabetes\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "diab_ct = np.zeros((2,2))\n",
    "\n",
    "#Since this variable is 1 for diabetes and 0 otherwise, we can just sum over the column\n",
    "diab_ct[0,0] = df_early[\"diabetes\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "diab_ct[0,1] = df_early.shape[0] - diab_ct[0,0]\n",
    "\n",
    "#Since this variable is 1 for diabetes and 0 otherwise, we can just sum over the column\n",
    "diab_ct[1,0] = df_later[\"diabetes\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "diab_ct[1,1] = df_later.shape[0] - diab_ct[1,0]\n",
    "\n",
    "#Print contingency table to csv\n",
    "total_diab = pd.DataFrame(data=diab_ct,columns=[\"diabetic\",\"not_diabetic\"],index=[\"early\",\"later\"])\n",
    "total_diab.to_csv('total_diabetes.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((diab_ct.shape[0],diab_ct.shape[1]))\n",
    "\n",
    "perc[0,:] = 100 * (np.divide(diab_ct[0,:],np.sum(diab_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(diab_ct[1,:],np.sum(diab_ct[1,:])))\n",
    "perc_diab = pd.DataFrame(data=perc,columns=[\"diabetic\",\"not_diabetic\"],index=[\"early\",\"later\"])\n",
    "perc_diab.to_csv('percentages_diabetes.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "diab_p = np.zeros((1,1))\n",
    "diab_p[0,0] = chi2_contingency(diab_ct)[1]\n",
    "p_val_diab = pd.DataFrame(data=diab_p,columns=['p-value of diabetes'])\n",
    "p_val_diab.to_csv('p_val_diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9c1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (vad_ct) for use of a ventricular assist device\n",
    "#The columns of the contingency table are as follows, in order\n",
    "#LVAD\n",
    "#other VAD\n",
    "#no VAD\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "\n",
    "#Because treatment variables are 1 for individuals with a given treatment, and 0 otherwise\n",
    "#We can find the number of patients with that treatment simply by summing over the column\n",
    "\n",
    "vad_ct = np.zeros((2,3))\n",
    "\n",
    "vad_ct[0,0] = df_early[\"lvad\"].sum()\n",
    "vad_ct[0,1] = df_early[\"other_vad\"].sum()\n",
    "vad_ct[0,2] = df_early[\"no_vad\"].sum()\n",
    "\n",
    "vad_ct[1,0] = df_later[\"lvad\"].sum()\n",
    "vad_ct[1,1] = df_later[\"other_vad\"].sum()\n",
    "vad_ct[1,2] = df_later[\"no_vad\"].sum()\n",
    "\n",
    "#Print contingency table to csv\n",
    "total_vad = pd.DataFrame(data=vad_ct,columns=[\"lvad\",\"other_vad\",\"no_vad\"],index=[\"early\",\"later\"])\n",
    "total_vad.to_csv('total_vad.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((vad_ct.shape[0],vad_ct.shape[1]))\n",
    "perc[0,:] = 100 * (np.divide(vad_ct[0,:],np.sum(vad_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(vad_ct[1,:],np.sum(vad_ct[1,:])))\n",
    "perc_vad = pd.DataFrame(data=perc,columns=[\"lvad\",\"other_vad\",\"no_vad\"],index=[\"early\",\"later\"])\n",
    "perc_vad.to_csv('percentages_vad.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "vad_p = np.zeros((1,1))\n",
    "vad_p[0,0] = chi2_contingency(vad_ct)[1]\n",
    "p_val_vad = pd.DataFrame(data=vad_p,columns=['p-value of VADs'])\n",
    "p_val_vad.to_csv('p_val_vad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7753f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (malig_ct) that has the number of individuals with a history of malignancy\n",
    "\n",
    "#The first column refers to people with a history of malignancy, and the second column to those without\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "malig_ct = np.zeros((2,2))\n",
    "\n",
    "#Since this variable is 1 for malignancy and 0 otherwise, we can just sum over the column\n",
    "malig_ct[0,0] = df_early[\"malig\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "malig_ct[0,1] = df_early.shape[0] - malig_ct[0,0]\n",
    "\n",
    "#Since this variable is 1 for malignancy and 0 otherwise, we can just sum over the column\n",
    "malig_ct[1,0] = df_later[\"malig\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "malig_ct[1,1] = df_later.shape[0] - malig_ct[1,0]\n",
    "\n",
    "#Print contingency table to csv\n",
    "total_malig = pd.DataFrame(data=malig_ct,columns=[\"malignancy\",\"no_malignancy\"],index=[\"early\",\"later\"])\n",
    "total_malig.to_csv('total_malig.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((malig_ct.shape[0],malig_ct.shape[1]))\n",
    "\n",
    "perc[0,:] = 100 * (np.divide(malig_ct[0,:],np.sum(malig_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(malig_ct[1,:],np.sum(malig_ct[1,:])))\n",
    "perc_malig = pd.DataFrame(data=perc,columns=[\"malignancy\",\"no malignancy\"],index=[\"early\",\"later\"])\n",
    "perc_malig.to_csv('percentages_malignancy.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "malig_p = np.zeros((1,1))\n",
    "malig_p[0,0] = chi2_contingency(malig_ct)[1]\n",
    "p_val_malig = pd.DataFrame(data=malig_p,columns=['p-value of malignancy'])\n",
    "p_val_malig.to_csv('p_val_malignancy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05839afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (tobac_ct) that has the number of individuals with a history of tobacco use\n",
    "\n",
    "#The first column refers to individuals with a history of tobacco use, and the second column to those without\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "tobac_ct = np.zeros((2,2))\n",
    "\n",
    "#Since this variable is 1 for tobacco use and 0 otherwise, we can just sum over the column\n",
    "tobac_ct[0,0] = df_early[\"tobacco\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "tobac_ct[0,1] = df_early.shape[0] - tobac_ct[0,0]\n",
    "\n",
    "#Since this variable is 1 for tobacco use and 0 otherwise, we can just sum over the column\n",
    "tobac_ct[1,0] = df_later[\"tobacco\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "tobac_ct[1,1] = df_later.shape[0] - tobac_ct[1,0]\n",
    "\n",
    "#Print contingency table to csv\n",
    "total_tobac = pd.DataFrame(data=tobac_ct,columns=[\"tobacco\",\"no_tobacco\"],index=[\"early\",\"later\"])\n",
    "total_tobac.to_csv('total_tobacco.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((tobac_ct.shape[0],tobac_ct.shape[1]))\n",
    "\n",
    "perc[0,:] = 100 * (np.divide(tobac_ct[0,:],np.sum(tobac_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(tobac_ct[1,:],np.sum(tobac_ct[1,:])))\n",
    "perc_tobac = pd.DataFrame(data=perc,columns=[\"tobacco\",\"no_tobacco\"],index=[\"early\",\"later\"])\n",
    "perc_tobac.to_csv('percentages_tobacco.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "tobac_p = np.zeros((1,1))\n",
    "tobac_p[0,0] = chi2_contingency(tobac_ct)[1]\n",
    "p_val_tobac = pd.DataFrame(data=tobac_p,columns=['p-value of tobacco'])\n",
    "p_val_tobac.to_csv('p_val_tobacco.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc9112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (blood_ct) that has the number of individuals with each blood type\n",
    "\n",
    "#Because blood type variables are 1 for individuals with a given type, and 0 otherwise\n",
    "#We can find the number of patients with that blood type simply by summing over the column\n",
    "#The columns of the contingency table are as follows, in order\n",
    "#A, AB, B, O\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "blood_ct = np.zeros((2,4))\n",
    "\n",
    "blood_ct[0,0] = df_early[\"blood_type_A\"].sum()\n",
    "blood_ct[0,1] = df_early[\"blood_type_AB\"].sum()\n",
    "blood_ct[0,2] = df_early[\"blood_type_B\"].sum()\n",
    "blood_ct[0,3] = df_early[\"blood_type_O\"].sum()\n",
    "\n",
    "blood_ct[1,0] = df_later[\"blood_type_A\"].sum()\n",
    "blood_ct[1,1] = df_later[\"blood_type_AB\"].sum()\n",
    "blood_ct[1,2] = df_later[\"blood_type_B\"].sum()\n",
    "blood_ct[1,3] = df_later[\"blood_type_O\"].sum()\n",
    "\n",
    "#Print contingency table to csv\n",
    "total_blood = pd.DataFrame(data=blood_ct,columns=[\"blood_type_A\",\"blood_type_AB\",\"blood_type_B\",\"blood_type_O\"],index=[\"early\",\"later\"])\n",
    "total_blood.to_csv('total_bloodtype.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((blood_ct.shape[0],blood_ct.shape[1]))\n",
    "perc[0,:] = 100 * (np.divide(blood_ct[0,:],np.sum(blood_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(blood_ct[1,:],np.sum(blood_ct[1,:])))\n",
    "perc_blood = pd.DataFrame(data=perc,columns=[\"blood_type_A\",\"blood_type_AB\",\"blood_type_B\",\"blood_type_O\"],index=[\"early\",\"later\"])\n",
    "perc_blood.to_csv('percentages_bloodtype.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "blood_p = np.zeros((1,1))\n",
    "blood_p[0,0] = chi2_contingency(blood_ct)[1]\n",
    "p_val_blood = pd.DataFrame(data=blood_p,columns=['p-value of blood type'])\n",
    "p_val_blood.to_csv('p_val_bloodtype.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec205e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (iabp_ct) that has the number of individuals with IABP treatment\n",
    "\n",
    "#The first column refers to individuals with IABP treatment, and the second to those without\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "iabp_ct = np.zeros((2,2))\n",
    "\n",
    "#Since this variable is 1 for IABP and 0 otherwise, we can just sum over the column\n",
    "iabp_ct[0,0] = df_early[\"CAN_IABP\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "iabp_ct[0,1] = df_early.shape[0] - iabp_ct[0,0]\n",
    "\n",
    "#Since this variable is 1 for IABP and 0 otherwise, we can just sum over the column\n",
    "iabp_ct[1,0] = df_later[\"CAN_IABP\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "iabp_ct[1,1] = df_later.shape[0] - iabp_ct[1,0]\n",
    "\n",
    "#Print contingency table to csv\n",
    "total_iabp = pd.DataFrame(data=iabp_ct,columns=[\"IABP\",\"No_IABP\"],index=[\"early\",\"later\"])\n",
    "total_iabp.to_csv('total_IABP.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((iabp_ct.shape[0],iabp_ct.shape[1]))\n",
    "perc[0,:] = 100 * (np.divide(iabp_ct[0,:],np.sum(iabp_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(iabp_ct[1,:],np.sum(iabp_ct[1,:])))\n",
    "perc_iabp = pd.DataFrame(data=perc,columns=[\"IABP\",\"No_IABP\"],index=[\"early\",\"later\"])\n",
    "perc_iabp.to_csv('percentages_IABP.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "iabp_p = np.zeros((1,1))\n",
    "iabp_p[0,0] = chi2_contingency(iabp_ct)[1]\n",
    "p_val_iabp = pd.DataFrame(data=iabp_p,columns=['p-value of IABP'])\n",
    "p_val_iabp.to_csv('p_val_IABP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba19da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (inotrop_ct) that has the number of individuals with IV Inotrope treatment\n",
    "\n",
    "#The first column refers to individuals with IV Inotrope treatment, and the second column to those without\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "inotrop_ct = np.zeros((2,2))\n",
    "\n",
    "#Since this variable is 1 for inotropes and 0 otherwise, we can just sum over the column\n",
    "inotrop_ct[0,0] = df_early[\"CAN_IV_INOTROP\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "inotrop_ct[0,1] = df_early.shape[0] - inotrop_ct[0,0]\n",
    "\n",
    "#Since this variable is 1 for inotropes and 0 otherwise, we can just sum over the column\n",
    "inotrop_ct[1,0] = df_later[\"CAN_IV_INOTROP\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "inotrop_ct[1,1] = df_later.shape[0] - inotrop_ct[1,0]\n",
    "\n",
    "#Print contingency table to csv\n",
    "total_inotrop = pd.DataFrame(data=inotrop_ct,columns=[\"Intropes\",\"No_Inotropes\"],index=[\"early\",\"later\"])\n",
    "total_inotrop.to_csv('total_inotropes.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((inotrop_ct.shape[0],inotrop_ct.shape[1]))\n",
    "perc[0,:] = 100 * (np.divide(inotrop_ct[0,:],np.sum(inotrop_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(inotrop_ct[1,:],np.sum(inotrop_ct[1,:])))\n",
    "perc_inotrop = pd.DataFrame(data=perc,columns=[\"Inotropes\",\"No_Inotropes\"],index=[\"early\",\"later\"])\n",
    "perc_inotrop.to_csv('percentages_inotropes.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "inotrop_p = np.zeros((1,1))\n",
    "inotrop_p[0,0] = chi2_contingency(inotrop_ct)[1]\n",
    "p_val_inotrop = pd.DataFrame(data=inotrop_p,columns=['p-value of IV Inotropes'])\n",
    "p_val_inotrop.to_csv('p_val_inotropes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27312110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (ecmo_ct) that has the number of individuals with ECMO treatment\n",
    "\n",
    "#The first column refers to individuals with ECMO treatment, and the second to those without\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "ecmo_ct = np.zeros((2,2))\n",
    "\n",
    "#Since this variable is 1 for ECMO and 0 otherwise, we can just sum over the column\n",
    "ecmo_ct[0,0] = df_early[\"CAN_ECMO\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "ecmo_ct[0,1] = df_early.shape[0] - ecmo_ct[0,0]\n",
    "\n",
    "#Since this variable is 1 for ECMO and 0 otherwise, we can just sum over the column\n",
    "ecmo_ct[1,0] = df_later[\"CAN_ECMO\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "ecmo_ct[1,1] = df_later.shape[0] - ecmo_ct[1,0]\n",
    "\n",
    "#Print contingency table to csv file\n",
    "total_ecmo = pd.DataFrame(data=ecmo_ct,columns=[\"ECMO\",\"No_ECMO\"],index=[\"early\",\"later\"])\n",
    "total_ecmo.to_csv('total_ECMO.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((ecmo_ct.shape[0],ecmo_ct.shape[1]))\n",
    "perc[0,:] = 100 * (np.divide(ecmo_ct[0,:],np.sum(ecmo_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(ecmo_ct[1,:],np.sum(ecmo_ct[1,:])))\n",
    "perc_ecmo = pd.DataFrame(data=perc,columns=[\"ECMO\",\"No_ECMO\"],index=[\"early\",\"later\"])\n",
    "perc_ecmo.to_csv('percentages_ECMO.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "ecmo_p = np.zeros((1,1))\n",
    "ecmo_p[0,0] = chi2_contingency(ecmo_ct)[1]\n",
    "p_val_ecmo = pd.DataFrame(data=ecmo_p,columns=['p-value of ECMO'])\n",
    "p_val_ecmo.to_csv('p_val_ECMO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf2e1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create contingency table (cereb_ct) that has the number of individuals with a history of cerebral vascular disease\n",
    "\n",
    "#The first column refers to those with a history of cerebral vascular disease, and the second column to those without\n",
    "#The first row refers to the early cohort, and the second row refers to the later cohort\n",
    "cereb_ct = np.zeros((2,2))\n",
    "\n",
    "#Since this variable is 1 for cerebral vascular disease and 0 otherwise, we can just sum over the column\n",
    "cereb_ct[0,0] = df_early[\"cereb_vasc\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "cereb_ct[0,1] = df_early.shape[0] - cereb_ct[0,0]\n",
    "\n",
    "#Since this variable is 1 for cerebral vascular disease and 0 otherwise, we can just sum over the column\n",
    "cereb_ct[1,0] = df_later[\"cereb_vasc\"].sum()\n",
    "#Then the number of 0 values is the remaining individuals in the cohort\n",
    "cereb_ct[1,1] = df_later.shape[0] - cereb_ct[1,0]\n",
    "\n",
    "#Print contingency table to csv file\n",
    "total_cereb = pd.DataFrame(data=cereb_ct,columns=[\"Cerebral_Vascular_Disease\",\"No_Cerebral_Vascular_Disease\"],index=[\"early\",\"later\"])\n",
    "total_cereb.to_csv('total_cerebral_vascular.csv')\n",
    "\n",
    "#Create array of percentages and print to csv\n",
    "perc = np.zeros((cereb_ct.shape[0],cereb_ct.shape[1]))\n",
    "perc[0,:] = 100 * (np.divide(cereb_ct[0,:],np.sum(cereb_ct[0,:])))\n",
    "perc[1,:] = 100 * (np.divide(cereb_ct[1,:],np.sum(cereb_ct[1,:])))\n",
    "perc_cereb = pd.DataFrame(data=perc,columns=[\"Cerebral_Vascular_Disease\",\"No_Cerebral_Vascular_Disease\"],index=[\"early\",\"later\"])\n",
    "perc_cereb.to_csv('percentages_cerebral_vascular.csv')\n",
    "\n",
    "#Calculate p-value for chi2 test and print to csv\n",
    "cereb_p = np.zeros((1,1))\n",
    "cereb_p[0,0] = chi2_contingency(cereb_ct)[1]\n",
    "p_val_cereb = pd.DataFrame(data=cereb_p,columns=['p-value of cerebral vascular disease'])\n",
    "p_val_cereb.to_csv('p_val_cerebral_vascular.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae169e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for age\n",
    "\n",
    "#First eliminate all cases with missing values for this variable\n",
    "age_early = df_early[[\"age\"]]\n",
    "missing_early = age_early[\"age\"].isna().sum()\n",
    "condition = (age_early[\"age\"].isna()==False)\n",
    "age_early = age_early[condition]\n",
    "\n",
    "age_later = df_later[[\"age\"]]\n",
    "missing_later = age_later[\"age\"].isna().sum()\n",
    "condition = (age_later[\"age\"].isna()==False)\n",
    "age_later = age_later[condition]\n",
    "\n",
    "#Convert to numpy for Wilcoxon test\n",
    "age_e = age_early.to_numpy()\n",
    "age_l = age_later.to_numpy()\n",
    "\n",
    "#Flatten arrays\n",
    "age_e = age_e.flatten()\n",
    "age_l = age_l.flatten()\n",
    "\n",
    "#Calculate the Wilcoxon rank-sum statistic\n",
    "w, p = ranksums(age_e,age_l)\n",
    "\n",
    "#Print all information calculated above to text file\n",
    "with open('age_stats.txt', 'w') as f:\n",
    "    print('p-value is', file=f)\n",
    "    print(p, file=f)\n",
    "    print('Median early is', file=f)\n",
    "    print(np.median(age_e), file=f)\n",
    "    print('25th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(age_e, 25), file=f)\n",
    "    print('75th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(age_e, 75), file=f)\n",
    "    print('Median later is', file=f)\n",
    "    print(np.median(age_l), file=f)\n",
    "    print('25th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(age_l, 25), file=f)\n",
    "    print('75th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(age_l, 75), file=f)\n",
    "    print('Number of missing values in early cohort was %6.0f' % missing_early, file=f)\n",
    "    print('Number of missing values in later cohort was %6.0f' % missing_later, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b0fde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for pulmonary capillary wedge pressure\n",
    "\n",
    "#First eliminate all cases with missing values for this variable\n",
    "pcw_early = df_early[[\"CAN_PCW_MEAN\"]]\n",
    "missing_early = pcw_early[\"CAN_PCW_MEAN\"].isna().sum()\n",
    "condition = (pcw_early[\"CAN_PCW_MEAN\"].isna()==False)\n",
    "pcw_early = pcw_early[condition]\n",
    "\n",
    "pcw_later = df_later[[\"CAN_PCW_MEAN\"]]\n",
    "missing_later = pcw_later[\"CAN_PCW_MEAN\"].isna().sum()\n",
    "condition = (pcw_later[\"CAN_PCW_MEAN\"].isna()==False)\n",
    "pcw_later = pcw_later[condition]\n",
    "\n",
    "#Convert to numpy for Wilcoxon test\n",
    "pcw_e = pcw_early.to_numpy()\n",
    "pcw_l = pcw_later.to_numpy()\n",
    "\n",
    "#Flatten arrays\n",
    "pcw_e = pcw_e.flatten()\n",
    "pcw_l = pcw_l.flatten()\n",
    "\n",
    "#Calculate the Wilcoxon rank-sum statistic\n",
    "w, p = ranksums(pcw_e,pcw_l)\n",
    "\n",
    "#Print all information calculated above to text file\n",
    "with open('pcw_stats.txt', 'w') as f:\n",
    "    print('p-value is', file=f)\n",
    "    print(p, file=f)\n",
    "    print('Median early is', file=f)\n",
    "    print(np.median(pcw_e), file=f)\n",
    "    print('25th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(pcw_e, 25), file=f)\n",
    "    print('75th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(pcw_e, 75), file=f)\n",
    "    print('Median later is', file=f)\n",
    "    print(np.median(pcw_l), file=f)\n",
    "    print('25th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(pcw_l, 25), file=f)\n",
    "    print('75th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(pcw_l, 75), file=f)\n",
    "    print('Number of missing values in early cohort was %6.0f' % missing_early, file=f)\n",
    "    print('Number of missing values in later cohort was %6.0f' % missing_later, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f970224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for BMI\n",
    "\n",
    "#First eliminate all cases with missing values for this variable\n",
    "bmi_early = df_early[[\"CAN_BMI\"]]\n",
    "missing_early = bmi_early[\"CAN_BMI\"].isna().sum()\n",
    "condition = (bmi_early[\"CAN_BMI\"].isna()==False)\n",
    "bmi_early = bmi_early[condition]\n",
    "\n",
    "bmi_later = df_later[[\"CAN_BMI\"]]\n",
    "missing_later = bmi_later[\"CAN_BMI\"].isna().sum()\n",
    "condition = (bmi_later[\"CAN_BMI\"].isna()==False)\n",
    "bmi_later = bmi_later[condition]\n",
    "\n",
    "#Convert to numpy for Wilcoxon test\n",
    "bmi_e = bmi_early.to_numpy()\n",
    "bmi_l = bmi_later.to_numpy()\n",
    "\n",
    "#Flatten arrays\n",
    "bmi_e = bmi_e.flatten()\n",
    "bmi_l = bmi_l.flatten()\n",
    "\n",
    "#Calculate Wilcoxon rank-sum statistic\n",
    "w, p = ranksums(bmi_e,bmi_l)\n",
    "\n",
    "#Print all information calculated above to text file\n",
    "with open('bmi_stats.txt', 'w') as f:\n",
    "    print('p-value is', file=f)\n",
    "    print(p, file=f)\n",
    "    print('Median early is', file=f)\n",
    "    print(np.median(bmi_e), file=f)\n",
    "    print('25th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(bmi_e, 25), file=f)\n",
    "    print('75th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(bmi_e, 75), file=f)\n",
    "    print('Median later is', file=f)\n",
    "    print(np.median(bmi_l), file=f)\n",
    "    print('25th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(bmi_l, 25), file=f)\n",
    "    print('75th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(bmi_l, 75), file=f)\n",
    "    print('Number of missing values in early cohort was %6.0f' % missing_early, file=f)\n",
    "    print('Number of missing values in later cohort was %6.0f' % missing_later, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be3d98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for glomerular filtration rate\n",
    "\n",
    "#First eliminate all cases with missing values for this variable\n",
    "gfr_early = df_early[[\"gfr\"]]\n",
    "missing_early = gfr_early[\"gfr\"].isna().sum()\n",
    "condition = (gfr_early[\"gfr\"].isna()==False)\n",
    "gfr_early = gfr_early[condition]\n",
    "\n",
    "gfr_later = df_later[[\"gfr\"]]\n",
    "missing_later = gfr_later[\"gfr\"].isna().sum()\n",
    "condition = (gfr_later[\"gfr\"].isna()==False)\n",
    "gfr_later = gfr_later[condition]\n",
    "\n",
    "#Convert to numpy for Wilcoxon test\n",
    "gfr_e = gfr_early.to_numpy()\n",
    "gfr_l = gfr_later.to_numpy()\n",
    "\n",
    "#Flatten arrays\n",
    "gfr_e = gfr_e.flatten()\n",
    "gfr_l = gfr_l.flatten()\n",
    "\n",
    "#Calculate Wilcoxon rank-sum statistic\n",
    "w, p = ranksums(gfr_e,gfr_l)\n",
    "\n",
    "#Print all information calculated above to text file\n",
    "with open('gfr_stats.txt', 'w') as f:\n",
    "    print('p-value is', file=f)\n",
    "    print(p, file=f)\n",
    "    print('Median early is', file=f)\n",
    "    print(np.median(gfr_e), file=f)\n",
    "    print('25th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(gfr_e, 25), file=f)\n",
    "    print('75th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(gfr_e, 75), file=f)\n",
    "    print('Median later is', file=f)\n",
    "    print(np.median(gfr_l), file=f)\n",
    "    print('25th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(gfr_l, 25), file=f)\n",
    "    print('75th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(gfr_l, 75), file=f)\n",
    "    print('Number of missing values in early cohort was %6.0f' % missing_early, file=f)\n",
    "    print('Number of missing values in later cohort was %6.0f' % missing_later, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7698517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for pulmonary artery mean pressure\n",
    "\n",
    "#First eliminate all cases with missing values for this variable\n",
    "pam_early = df_early[[\"CAN_PULM_ART_MEAN\"]]\n",
    "missing_early = pam_early[\"CAN_PULM_ART_MEAN\"].isna().sum()\n",
    "condition = (pam_early[\"CAN_PULM_ART_MEAN\"].isna()==False)\n",
    "pam_early = pam_early[condition]\n",
    "\n",
    "pam_later = df_later[[\"CAN_PULM_ART_MEAN\"]]\n",
    "missing_later = pam_later[\"CAN_PULM_ART_MEAN\"].isna().sum()\n",
    "condition = (pam_later[\"CAN_PULM_ART_MEAN\"].isna()==False)\n",
    "pam_later = pam_later[condition]\n",
    "\n",
    "#Convert to numpy for Wilcoxon test\n",
    "pam_e = pam_early.to_numpy()\n",
    "pam_l = pam_later.to_numpy()\n",
    "\n",
    "#Flatten arrays\n",
    "pam_e = pam_e.flatten()\n",
    "pam_l = pam_l.flatten()\n",
    "\n",
    "#Calculate Wilcoxon rank-sum statistic\n",
    "w, p = ranksums(pam_e,pam_l)\n",
    "\n",
    "#Print all information calculated above to text file\n",
    "with open('pam_stats.txt', 'w') as f:\n",
    "    print('p-value is', file=f)\n",
    "    print(p, file=f)\n",
    "    print('Median early is', file=f)\n",
    "    print(np.median(pam_e), file=f)\n",
    "    print('25th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(pam_e, 25), file=f)\n",
    "    print('75th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(pam_e, 75), file=f)\n",
    "    print('Median later is', file=f)\n",
    "    print(np.median(pam_l), file=f)\n",
    "    print('25th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(pam_l, 25), file=f)\n",
    "    print('75th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(pam_l, 75), file=f)\n",
    "    print('Number of missing values in early cohort was %6.0f' % missing_early, file=f)\n",
    "    print('Number of missing values in later cohort was %6.0f' % missing_later, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6f8cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for cardiac index\n",
    "\n",
    "#First eliminate all cases with missing values for this variable\n",
    "ci_early = df_early[[\"cardiac_index\"]]\n",
    "missing_early = ci_early[\"cardiac_index\"].isna().sum()\n",
    "condition = (ci_early[\"cardiac_index\"].isna()==False)\n",
    "ci_early = ci_early[condition]\n",
    "\n",
    "ci_later = df_later[[\"cardiac_index\"]]\n",
    "missing_later = ci_later[\"cardiac_index\"].isna().sum()\n",
    "condition = (ci_later[\"cardiac_index\"].isna()==False)\n",
    "ci_later = ci_later[condition]\n",
    "\n",
    "#Convert to numpy for Wilcoxon test\n",
    "ci_e = ci_early.to_numpy()\n",
    "ci_l = ci_later.to_numpy()\n",
    "\n",
    "#Flatten arrays\n",
    "ci_e = ci_e.flatten()\n",
    "ci_l = ci_l.flatten()\n",
    "\n",
    "#Calculate Wilcoxon rank-sum statistic\n",
    "w, p = ranksums(ci_e,ci_l)\n",
    "\n",
    "#Print all information calculated above to text file\n",
    "with open('cardiac_index_stats.txt', 'w') as f:\n",
    "    print('p-value is', file=f)\n",
    "    print(p, file=f)\n",
    "    print('Median early is', file=f)\n",
    "    print(np.median(ci_e), file=f)\n",
    "    print('25th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(ci_e, 25), file=f)\n",
    "    print('75th percentile, early cohort, is', file=f)\n",
    "    print(np.percentile(ci_e, 75), file=f)\n",
    "    print('Median later is', file=f)\n",
    "    print(np.median(ci_l), file=f)\n",
    "    print('25th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(ci_l, 25), file=f)\n",
    "    print('75th percentile, later cohort, is', file=f)\n",
    "    print(np.percentile(ci_l, 75), file=f)\n",
    "    print('Number of missing values in early cohort was %6.0f' % missing_early, file=f)\n",
    "    print('Number of missing values in later cohort was %6.0f' % missing_later, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20131c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.9690035300675\n"
     ]
    }
   ],
   "source": [
    "age_total = np.append(age_e,age_l)\n",
    "mean_age = np.mean(age_total)\n",
    "print(mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "420dcd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7373815569455626\n"
     ]
    }
   ],
   "source": [
    "#Percentage male in data\n",
    "male = df[df['CAN_GENDER']=='M']\n",
    "perc_male = male.shape[0]/df.shape[0]\n",
    "print(perc_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9abde67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4740"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number died and transplanted\n",
    "condition = (df['dead']==1) & (df['transplanted']==1)\n",
    "count_deadT = df[condition]\n",
    "count_deadT.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bfe8dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17307"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number transplanted and alive\n",
    "condition = (df['dead']==0) & (df['transplanted']==1)\n",
    "count_AT = df[condition]\n",
    "count_AT.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1efa52db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number not transplanted and died\n",
    "condition = (df['dead']==1) & (df['transplanted']==0)\n",
    "count_deadN = df[condition]\n",
    "count_deadN.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2479bd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4747"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number not transplanted and alive\n",
    "condition = (df['dead']==0) & (df['transplanted']==0)\n",
    "count_AN = df[condition]\n",
    "count_AN.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97805d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22047"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number transplanted\n",
    "condition = (df['transplanted']==1)\n",
    "count_T = df[condition]\n",
    "count_T.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce85fdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32294"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number analyzed\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc5f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
